#!/usr/bin/env python3
"""
SeqSetVAE æ¨¡å‹é‡å¤æ—¥å¿—è®°å½•ä¿®å¤è„šæœ¬
========================================

ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ¥ä¿®å¤ä½ çš„SeqSetVAEæ¨¡å‹ä¸­çš„é‡å¤æ—¥å¿—è®°å½•é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•:
python fix_seqsetvae_model.py /path/to/your/SeqSetVAE/main/model.py
"""

import os
import re
import sys
import shutil
from datetime import datetime

def fix_duplicate_logging(model_file_path):
    """
    ä¿®å¤PyTorch Lightningæ¨¡å‹ä¸­çš„é‡å¤æ—¥å¿—è®°å½•é—®é¢˜
    
    é”™è¯¯: You called `self.log(val/focal_loss, ...)` twice in `validation_step` 
          with different arguments. This is not allowed
    """
    
    if not os.path.exists(model_file_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {model_file_path}")
        return False
    
    print(f"ğŸ”§ æ­£åœ¨ä¿®å¤æ¨¡å‹æ–‡ä»¶: {model_file_path}")
    
    # è¯»å–åŸæ–‡ä»¶
    try:
        with open(model_file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºå¤‡ä»½
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{model_file_path}.backup_{timestamp}"
    try:
        shutil.copy2(model_file_path, backup_path)
        print(f"âœ… å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
    except Exception as e:
        print(f"âš ï¸  å¤‡ä»½å¤±è´¥: {e}")
    
    modified_content = original_content
    changes_made = []
    
    # 1. ä¿®å¤ _step æ–¹æ³•
    step_pattern = r'(def _step\(self, batch, stage.*?\):)(.*?)(?=\n    def |\n\nclass |\nclass |\Z)'
    
    def replace_step_method(match):
        method_signature = match.group(1)
        method_body = match.group(2)
        
        # æ–°çš„_stepæ–¹æ³•å®ç°
        new_method = f'''{method_signature}
        """ç»Ÿä¸€å¤„ç†æ‰€æœ‰é˜¶æ®µçš„æ—¥å¿—è®°å½• - ä¿®å¤é‡å¤æ—¥å¿—è®°å½•é—®é¢˜"""
        # åŸæœ‰è®¡ç®—é€»è¾‘
        logits, recon_loss, kl_loss = self(batch)
        
        # è®¡ç®—focal loss
        if hasattr(self, 'calculate_focal_loss'):
            focal_loss = self.calculate_focal_loss(logits, batch)
        else:
            # å¦‚æœæ²¡æœ‰focal_lossæ–¹æ³•ï¼Œä½¿ç”¨BCEä½œä¸ºæ›¿ä»£
            import torch.nn.functional as F
            labels = batch.get('label', batch.get('labels', batch.get('target')))
            focal_loss = F.binary_cross_entropy_with_logits(logits, labels.float())
        
        total_loss = focal_loss + recon_loss + kl_loss
        
        # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹
        import torch
        probs = torch.sigmoid(logits)
        preds = (probs > 0.5).int()
        label = batch.get('label', batch.get('labels', batch.get('target')))
        
        # æ›´æ–°torchmetricsï¼ˆä¸è‡ªåŠ¨è®°å½•æ—¥å¿—ï¼‰
        if stage == "val":
            if hasattr(self, 'val_auc') and self.val_auc is not None:
                self.val_auc.update(probs, label)
            if hasattr(self, 'val_auprc') and self.val_auprc is not None:
                self.val_auprc.update(probs, label)
            if hasattr(self, 'val_acc') and self.val_acc is not None:
                self.val_acc.update(preds, label)
        elif stage == "train":
            if hasattr(self, 'train_auc') and self.train_auc is not None:
                self.train_auc.update(probs, label)
            if hasattr(self, 'train_acc') and self.train_acc is not None:
                self.train_acc.update(preds, label)
        
        # *** å…³é”®ä¿®æ”¹ï¼šç»Ÿä¸€è®°å½•æ‰€æœ‰æŒ‡æ ‡ï¼Œé¿å…é‡å¤ ***
        log_metrics = {{
            f"{{stage}}/focal_loss": focal_loss,
            f"{{stage}}/recon_loss": recon_loss,
            f"{{stage}}/kl_loss": kl_loss,
            f"{{stage}}/total_loss": total_loss,
        }}
        
        # æ ¹æ®é˜¶æ®µé€‰æ‹©åˆé€‚çš„æ—¥å¿—è®°å½•å‚æ•°
        if stage == "train":
            self.log_dict(log_metrics, prog_bar=True, logger=True, on_step=True, on_epoch=True, sync_dist=True)
        else:  # val or test
            self.log_dict(log_metrics, prog_bar=True, logger=True, on_step=False, on_epoch=True, sync_dist=True)
        
        # å¤„ç†splitdataæ¨¡å—å†²çª
        if hasattr(self, 'splitdata_module') and stage == "val":
            try:
                split_metrics = self._get_splitdata_metrics(batch, stage)
                if split_metrics:
                    # ä½¿ç”¨ä¸åŒçš„é”®åé¿å…å†²çª
                    split_log_metrics = {{f"{{stage}}/split_{{k}}": v for k, v in split_metrics.items()}}
                    self.log_dict(split_log_metrics, prog_bar=False, logger=True, on_step=False, on_epoch=True, sync_dist=True)
            except Exception as e:
                print(f"Warning: splitdata logging error: {{e}}")
        
        return logits, recon_loss, kl_loss'''
        
        return new_method
    
    if re.search(step_pattern, modified_content, re.DOTALL):
        modified_content = re.sub(step_pattern, replace_step_method, modified_content, flags=re.DOTALL)
        changes_made.append("âœ… ä¿®å¤äº† _step æ–¹æ³•")
    else:
        print("âš ï¸  æœªæ‰¾åˆ° _step æ–¹æ³•")
    
    # 2. ä¿®å¤ validation_step æ–¹æ³•
    val_step_pattern = r'(def validation_step\(self, batch, batch_idx.*?\):)(.*?)(?=\n    def |\n\nclass |\nclass |\Z)'
    
    def replace_validation_step(match):
        method_signature = match.group(1)
        
        new_method = f'''{method_signature}
        """ç®€åŒ–çš„validation_step - åªè°ƒç”¨_stepï¼Œé¿å…é‡å¤æ—¥å¿—è®°å½•"""
        # *** åˆ é™¤æ‰€æœ‰åŸæœ‰çš„ self.log() è°ƒç”¨ ***
        logits, recon_loss, kl_loss = self._step(batch, "val")
        
        # è¿”å›å¿…è¦çš„ä¿¡æ¯ç»™Lightning
        return {{"val_loss": recon_loss + kl_loss}}'''
        
        return new_method
    
    if re.search(val_step_pattern, modified_content, re.DOTALL):
        modified_content = re.sub(val_step_pattern, replace_validation_step, modified_content, flags=re.DOTALL)
        changes_made.append("âœ… ä¿®å¤äº† validation_step æ–¹æ³•")
    else:
        print("âš ï¸  æœªæ‰¾åˆ° validation_step æ–¹æ³•")
    
    # 3. æ·»åŠ è¾…åŠ©æ–¹æ³•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if '_get_splitdata_metrics' not in modified_content:
        helper_method = '''
    def _get_splitdata_metrics(self, batch, stage):
        """è·å–splitdataæ¨¡å—çš„æŒ‡æ ‡ï¼Œä½¿ç”¨ä¸åŒé”®åé¿å…å†²çª"""
        if not hasattr(self, 'splitdata_module'):
            return {}
        
        metrics = {}
        try:
            if hasattr(self.splitdata_module, 'calculate_loss'):
                split_loss = self.splitdata_module.calculate_loss(batch)
                metrics['focal_loss'] = split_loss  # å°†è¢«è®°å½•ä¸º val/split_focal_loss
                
            if hasattr(self.splitdata_module, 'calculate_accuracy'):
                split_acc = self.splitdata_module.calculate_accuracy(batch)
                metrics['accuracy'] = split_acc  # å°†è¢«è®°å½•ä¸º val/split_accuracy
                
        except Exception as e:
            print(f"Error in splitdata metrics calculation: {e}")
        
        return metrics
'''
        
        # åœ¨ç±»çš„æœ«å°¾æ·»åŠ è¾…åŠ©æ–¹æ³•
        class_pattern = r'(\n\s*def configure_optimizers.*?return.*?\n)'
        if re.search(class_pattern, modified_content, re.DOTALL):
            modified_content = re.sub(class_pattern, r'\1' + helper_method, modified_content, flags=re.DOTALL)
        else:
            # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
            modified_content += helper_method
        
        changes_made.append("âœ… æ·»åŠ äº† _get_splitdata_metrics è¾…åŠ©æ–¹æ³•")
    
    # 4. å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
    try:
        with open(model_file_path, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        print(f"âœ… ä¿®å¤å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜: {model_file_path}")
    except Exception as e:
        print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # æ˜¾ç¤ºä¿®å¤ç»“æœ
    if changes_made:
        print("\nğŸ‰ ä¿®å¤æ‘˜è¦:")
        for change in changes_made:
            print(f"  {change}")
    else:
        print("âš ï¸  æœªè¿›è¡Œä»»ä½•ä¿®æ”¹")
    
    print(f"\nğŸ“‹ éªŒè¯æ­¥éª¤:")
    print("1. è¿è¡Œè®­ç»ƒè„šæœ¬æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡å¤æ—¥å¿—è®°å½•é”™è¯¯")
    print("2. æ£€æŸ¥tensorboardä¸­æŒ‡æ ‡æ˜¯å¦æ­£å¸¸æ˜¾ç¤º")
    print("3. å¦‚æœæœ‰é—®é¢˜ï¼Œå¯ä»¥ä»å¤‡ä»½æ–‡ä»¶æ¢å¤:")
    print(f"   cp {backup_path} {model_file_path}")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python fix_seqsetvae_model.py <model_file_path>")
        print("ç¤ºä¾‹: python fix_seqsetvae_model.py /home/sunx/data/aiiih/projects/sunx/projects/SeqSetVAE/main/model.py")
        sys.exit(1)
    
    model_file_path = sys.argv[1]
    
    print("ğŸš€ SeqSetVAE é‡å¤æ—¥å¿—è®°å½•ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    success = fix_duplicate_logging(model_file_path)
    
    if success:
        print("\nâœ… ä¿®å¤æˆåŠŸï¼")
        sys.exit(0)
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()